{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для задания были выбраны тексты с омонимами. Определение части речи здесь полностью зависит от контекста,\n",
    "так что для теггеров задание сильно усложняется.\n",
    "\n",
    "Создадим функции для чтения текстов из файлов и уберем из них пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/st/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-b14dfa26367a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'punkt'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mdir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscript\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrealpath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "dir, script = os.path.split(os.path.realpath(__file__))\n",
    "\n",
    "\n",
    "def getText(filename):\n",
    "    with open(dir + filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(\"“\", \"\", text)\n",
    "    text = re.sub(\"”\", \"\", text)\n",
    "    text = re.sub(\"–\", \"\", text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь для каждого теггера реализуем собственно функцию с теггированием."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def natashaTag(text):\n",
    "    from natasha import (\n",
    "        Segmenter,\n",
    "        NewsEmbedding,\n",
    "        NewsMorphTagger,\n",
    "        Doc\n",
    "    )\n",
    "    segmenter = Segmenter()\n",
    "\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    result = \"\"\n",
    "    for item in doc.tokens:\n",
    "        result += item.text + \" [\" + str(item.pos) + \"] \"\n",
    "    return result\n",
    "\n",
    "\n",
    "def pyMorphyTag(text):\n",
    "    import pymorphy2\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    result = \"\"\n",
    "    for word in words:\n",
    "        parsed = morph.parse(word)[0]\n",
    "        result += word + \" [\" + str(parsed.tag.POS) + \"] \"\n",
    "    return result\n",
    "\n",
    "\n",
    "def myStemTag(text):\n",
    "    import pymystem3\n",
    "    myStem = pymystem3.Mystem()\n",
    "    parsed = myStem.analyze(text)\n",
    "    result = \"\"\n",
    "    for item in parsed:\n",
    "        try:\n",
    "            temp = item[\"analysis\"]\n",
    "            tag = str(item[\"analysis\"][0][\"gr\"].split(\",\")[0])\n",
    "            tag = tag.split(\"=\")[0]\n",
    "            result += item[\"text\"] + \" [\" + tag + \"] \"\n",
    "        except:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "\n",
    "def flairTag(text):\n",
    "    from flair.data import Sentence\n",
    "    from flair.models import SequenceTagger\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    tagger = SequenceTagger.load('pos')\n",
    "    result = \"\"\n",
    "    for sentence in sentences:\n",
    "        sentence = Sentence(sentence)\n",
    "        tagger.predict(sentence)\n",
    "        sentence.clear_embeddings()\n",
    "        result += sentence.to_tagged_string()\n",
    "    result = re.sub(\"<\", \"[\", result)\n",
    "    result = re.sub(\">\", \"]\", result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def spacyTag(text):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    result = \"\"\n",
    "    for i, s in enumerate(doc.sents):\n",
    "        for t in s:\n",
    "            if t.pos_ != 'SPACE' and t.pos_ != 'PUNCT':\n",
    "                result += t.text + \" [\" + str(t.pos_) + \"] \"\n",
    "    return result\n",
    "\n",
    "\n",
    "def nltkTag(text):\n",
    "    nltk_text = nltk.word_tokenize(text)\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    result = \"\"\n",
    "    for item in nltk.pos_tag(nltk_text):\n",
    "        result += item[0] + \" [\" + str(item[1]) + \"] \"\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь унифицируем теги, чтобы получились как в нашем исходном файле"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unifyTags(text):\n",
    "    pos = {}\n",
    "    pos[\"noun\"] = [\"NN\", \"NNS\", \"S\", \"NOUN\", \"NNP\", \"PROPN\"]\n",
    "    pos[\"verb\"] = [\"VBD\", \"VB\", \"MD\", \"VBP\", \"V\", \"VERB\", \"INFN\", \"VBZ\", \"AUX\", \"VBN\"]\n",
    "    pos[\"adj\"] = [\"JJ\", \"A\", \"ADJ\", \"ADJF\", \"ADJS\"]\n",
    "    pos[\"pronoun\"] = [\"PRP\", \"WP\", \"PRP$\", \"ADVPRO\", \"APRO\", \"SPRO\", \"PRON\", \"NPRO\", \"WDT\"]\n",
    "    pos[\"article\"] = [\"DT\", \"DET\"]\n",
    "    pos[\"adverb\"] = [\"WRB\", \"ADV\", \"ADVB\", \"RB\"]\n",
    "    pos[\"conj\"] = [\"CONJ\", \"CC\", \"CCONJ\", \"SCONJ\"]\n",
    "    pos[\"num\"] = [\"NUMR\", \"CD\", \"NUM\"]\n",
    "    pos[\"prep\"] = [\"ADP\", \"IN\", \"PR\", \"RP\", \"PREP\"]\n",
    "    pos[\"clitic\"] = [\"PART\", \"PRCL\"]\n",
    "    pos[\"interjection\"] = [\"UH\"]\n",
    "\n",
    "    words = text.split(\" \")\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if word.startswith(\"[\"):\n",
    "            word = re.sub(\"\\[\", \"\", word)\n",
    "            word = re.sub(\"]\", \"\", word)\n",
    "            for part in pos:\n",
    "                if word in pos[part]:\n",
    "                    res.append(part)\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            res.append(word)\n",
    "\n",
    "    return \" \".join(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наконец, функция подсчета accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def checkAccuracy(machineTagged, tagged):\n",
    "    machineWords = machineTagged.split(\" \")\n",
    "    words = tagged.split(\" \")\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    while i < len(words):\n",
    "        if words[i] != machineWords[i]:\n",
    "            print(\"ERROR!!!\")\n",
    "            print(words[i], machineWords[i])\n",
    "        i += 1\n",
    "        if words[i] == machineWords[i]:\n",
    "            correct += 1\n",
    "        i += 1\n",
    "    return correct * 2 / len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "И запустим все вычисления"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = getText(\"/rus.txt\")\n",
    "tagged_text = getText(\"/rus_tagged.txt\")\n",
    "print(\"NATASHA\")\n",
    "print(checkAccuracy(unifyTags(natashaTag(text)), tagged_text))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"PYMORPHY\")\n",
    "print(checkAccuracy(unifyTags(pyMorphyTag(text)), tagged_text))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"MYSTEM\")\n",
    "print(checkAccuracy(unifyTags(myStemTag(text)), tagged_text))\n",
    "print()\n",
    "\n",
    "text = getText(\"/eng.txt\")\n",
    "tagged_text = getText(\"/eng_tagged.txt\")\n",
    "print(\"FLAIR\")\n",
    "print(checkAccuracy(unifyTags(flairTag(text)), tagged_text))\n",
    "print()\n",
    "\n",
    "print(\"SPACY\")\n",
    "print(checkAccuracy(unifyTags(spacyTag(text)), tagged_text))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"NLTK\")\n",
    "print(checkAccuracy(unifyTags(nltkTag(text)), tagged_text))\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}